{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a64b4b57",
   "metadata": {},
   "source": [
    "## 5. H2O AutoML and Hyperparameter Search\n",
    "\n",
    "We run AutoML after establishing baselines. AutoML explores multiple model families and hyperparameters to find strong candidates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b8f9b",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "We load core libraries and enable the local H2O environment.\n",
    "\n",
    "Logs will be written to ./h2o_logs and H2O will run in verbose mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c1bec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure h2o is available from /tmp/pydeps\n",
    "sys.path.insert(0, '/tmp/pydeps')\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3871455",
   "metadata": {},
   "source": [
    "## 2. Data loading\n",
    "\n",
    "We load the OULAD CSV files and build the same final dataset used in the main notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9787a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DATA_DIR: d:\\Project\\DBM_FINAL\n"
     ]
    }
   ],
   "source": [
    "# CHANGE THIS to your local folder containing the 7 OULAD CSV files\n",
    "DEFAULT_DATA_DIR = os.path.join('.', 'data', 'oulad')\n",
    "\n",
    "required_files = [\n",
    "    'assessments.csv','courses.csv','studentAssessment.csv','studentInfo.csv',\n",
    "    'studentRegistration.csv','studentVle.csv','vle.csv'\n",
    "]\n",
    "\n",
    "# Resolve DATA_DIR from common locations\n",
    "candidate_dirs = [DEFAULT_DATA_DIR, '.']\n",
    "resolved = None\n",
    "for d in candidate_dirs:\n",
    "    if all(os.path.exists(os.path.join(d, f)) for f in required_files):\n",
    "        resolved = d\n",
    "        break\n",
    "\n",
    "if resolved is None:\n",
    "    missing = [f for f in required_files if not os.path.exists(os.path.join(DEFAULT_DATA_DIR, f))]\n",
    "    print('Missing files in DEFAULT_DATA_DIR:', missing)\n",
    "    print('DEFAULT_DATA_DIR currently set to:', os.path.abspath(DEFAULT_DATA_DIR))\n",
    "    print('Also checked:', os.path.abspath('.'))\n",
    "else:\n",
    "    DATA_DIR = resolved\n",
    "    print('Using DATA_DIR:', os.path.abspath(DATA_DIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465d0c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(name, usecols=None, dtype=None):\n",
    "    path = os.path.join(DATA_DIR, name)\n",
    "    return pd.read_csv(path, usecols=usecols, dtype=dtype, low_memory=False)\n",
    "\n",
    "assessments = read_csv('assessments.csv')\n",
    "courses = read_csv('courses.csv')\n",
    "student_info = read_csv('studentInfo.csv')\n",
    "student_reg = read_csv('studentRegistration.csv')\n",
    "student_assess = read_csv('studentAssessment.csv')\n",
    "vle = read_csv('vle.csv')\n",
    "\n",
    "student_vle = read_csv(\n",
    "    'studentVle.csv',\n",
    "    usecols=['code_module','code_presentation','id_student','id_site','date','sum_click'],\n",
    "    dtype={\n",
    "        'code_module':'category','code_presentation':'category',\n",
    "        'id_student':'int32','id_site':'int32',\n",
    "        'date':'int16','sum_click':'int32'\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bba78ad",
   "metadata": {},
   "source": [
    "## 3. Cleaning and feature engineering\n",
    "\n",
    "We apply the same cleaning and feature engineering used in the main notebook, then drop leakage features and remove zero-activity rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8bcdd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- assessments: drop known invalid IDs\n",
    "invalid_ids = {40087, 40088}\n",
    "assessments = assessments[~assessments['id_assessment'].isin(invalid_ids)].copy()\n",
    "assessments['weight'] = pd.to_numeric(assessments['weight'], errors='coerce')\n",
    "assessments['date'] = pd.to_numeric(assessments['date'], errors='coerce')\n",
    "\n",
    "# --- studentAssessment: clean score/date\n",
    "student_assess['score'] = student_assess['score'].replace(['?', '', ' '], np.nan)\n",
    "student_assess['score'] = pd.to_numeric(student_assess['score'], errors='coerce')\n",
    "student_assess['date_submitted'] = pd.to_numeric(student_assess['date_submitted'], errors='coerce')\n",
    "student_assess['is_banked'] = pd.to_numeric(student_assess['is_banked'], errors='coerce').fillna(0).astype(int)\n",
    "student_assess = student_assess.dropna(subset=['score']).copy()\n",
    "\n",
    "# --- studentInfo cleanup\n",
    "student_info['imd_band'] = student_info['imd_band'].replace('?', np.nan)\n",
    "student_info['age_band'] = student_info['age_band'].replace({'55<=': '>=55'})\n",
    "\n",
    "# --- studentVle: drop duplicates\n",
    "student_vle = student_vle.drop_duplicates().copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c72f7637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Than Minh\\AppData\\Local\\Temp\\ipykernel_39844\\1098740652.py:50: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  vle_type_pivot = vle_type_agg.pivot_table(\n"
     ]
    }
   ],
   "source": [
    "# --- target\n",
    "student_info['final_result_upd'] = student_info['final_result'].replace({\n",
    "    'Distinction': 'Pass',\n",
    "    'Withdrawn': 'Fail'\n",
    "})\n",
    "student_info = student_info[student_info['final_result_upd'].isin(['Pass','Fail'])].copy()\n",
    "student_info['final_result_upd_numeric'] = (student_info['final_result_upd'] == 'Pass').astype(int)\n",
    "\n",
    "# --- VLE aggregates\n",
    "vle_agg = (\n",
    "    student_vle\n",
    "    .groupby(['id_student','code_module','code_presentation'], as_index=False, observed=True)\n",
    "    .agg(\n",
    "        total_sum_click=('sum_click','sum'),\n",
    "        active_days=('date','nunique'),\n",
    "        distinct_sites=('id_site','nunique')\n",
    "    )\n",
    ")\n",
    "\n",
    "early = student_vle[student_vle['date'] <= 14]\n",
    "early_agg = (\n",
    "    early.groupby(['id_student','code_module','code_presentation'], as_index=False, observed=True)\n",
    "         .agg(early_sum_click=('sum_click','sum'), early_active_days=('date','nunique'))\n",
    ")\n",
    "\n",
    "vle_features = vle_agg.merge(early_agg, on=['id_student','code_module','code_presentation'], how='left')\n",
    "vle_features[['early_sum_click','early_active_days']] = vle_features[['early_sum_click','early_active_days']].fillna(0)\n",
    "\n",
    "vle_features['early_click_ratio'] = vle_features['early_sum_click'] / vle_features['total_sum_click'].replace(0, np.nan)\n",
    "vle_features['early_click_ratio'] = vle_features['early_click_ratio'].fillna(0)\n",
    "\n",
    "vle_features['clicks_per_active_day'] = vle_features['total_sum_click'] / vle_features['active_days'].replace(0, np.nan)\n",
    "vle_features['clicks_per_active_day'] = vle_features['clicks_per_active_day'].fillna(0)\n",
    "\n",
    "vle_features['early_clicks_per_active_day'] = vle_features['early_sum_click'] / vle_features['early_active_days'].replace(0, np.nan)\n",
    "vle_features['early_clicks_per_active_day'] = vle_features['early_clicks_per_active_day'].fillna(0)\n",
    "\n",
    "vle_features['early_active_ratio'] = vle_features['early_active_days'] / vle_features['active_days'].replace(0, np.nan)\n",
    "vle_features['early_active_ratio'] = vle_features['early_active_ratio'].fillna(0)\n",
    "\n",
    "# activity type aggregates\n",
    "vle_types = student_vle.merge(vle[['id_site','activity_type']], on='id_site', how='left')\n",
    "\n",
    "vle_type_agg = (\n",
    "    vle_types.groupby(['id_student','code_module','code_presentation','activity_type'], observed=True)\n",
    "             .agg(type_clicks=('sum_click','sum'))\n",
    "             .reset_index()\n",
    ")\n",
    "\n",
    "vle_type_pivot = vle_type_agg.pivot_table(\n",
    "    index=['id_student','code_module','code_presentation'],\n",
    "    columns='activity_type',\n",
    "    values='type_clicks',\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "for col in vle_type_pivot.columns:\n",
    "    if col not in ['id_student','code_module','code_presentation']:\n",
    "        vle_type_pivot = vle_type_pivot.rename(columns={col: f'clicks_type_{col}'})\n",
    "\n",
    "vle_features = vle_features.merge(vle_type_pivot, on=['id_student','code_module','code_presentation'], how='left')\n",
    "\n",
    "# diversity features\n",
    "activity_cols = [c for c in vle_features.columns if c.startswith('clicks_type_')]\n",
    "type_sum = vle_features[activity_cols].sum(axis=1).replace(0, np.nan)\n",
    "type_probs = vle_features[activity_cols].div(type_sum, axis=0).fillna(0)\n",
    "vle_features['distinct_activity_types'] = (vle_features[activity_cols] > 0).sum(axis=1)\n",
    "vle_features['activity_entropy'] = -(type_probs * np.log(type_probs + 1e-9)).sum(axis=1)\n",
    "vle_features['top_type_share'] = type_probs.max(axis=1)\n",
    "\n",
    "vle_features['log1p_total_sum_click'] = np.log1p(vle_features['total_sum_click'])\n",
    "vle_features['log1p_early_sum_click'] = np.log1p(vle_features['early_sum_click'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc6fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- assessment features (kept for completeness, later dropped)\n",
    "sa = student_assess.merge(\n",
    "    assessments[['id_assessment','code_module','code_presentation','assessment_type','weight','date']],\n",
    "    on='id_assessment', how='left'\n",
    ")\n",
    "\n",
    "sa['weighted_score'] = np.where(sa['is_banked'] == 1, 0, sa['score'] * (sa['weight'] / 100.0))\n",
    "sa['lateness_days'] = sa['date_submitted'] - sa['date']\n",
    "\n",
    "assess_agg = (\n",
    "    sa.groupby(['id_student','code_module','code_presentation'], as_index=False, observed=True)\n",
    "      .agg(\n",
    "          exam_weighted=('weighted_score', lambda x: x[sa.loc[x.index,'assessment_type'].eq('Exam')].sum()),\n",
    "          non_exam_weighted=('weighted_score', lambda x: x[~sa.loc[x.index,'assessment_type'].eq('Exam')].sum()),\n",
    "          mean_score=('score','mean'),\n",
    "          late_submissions=('lateness_days', lambda s: (s>0).sum())\n",
    "      )\n",
    ")\n",
    "\n",
    "assess_agg['has_exam'] = (assess_agg['exam_weighted'] > 0).astype(int)\n",
    "assess_agg['has_non_exam'] = (assess_agg['non_exam_weighted'] > 0).astype(int)\n",
    "assess_agg['overall_grade'] = np.where(\n",
    "    (assess_agg['has_exam']==1) & (assess_agg['has_non_exam']==1),\n",
    "    (assess_agg['exam_weighted'] + assess_agg['non_exam_weighted']) / 2.0,\n",
    "    np.where(assess_agg['has_exam']==1, assess_agg['exam_weighted'], assess_agg['non_exam_weighted'])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20aadec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- registration features\n",
    "student_reg['date_registration'] = pd.to_numeric(student_reg['date_registration'], errors='coerce')\n",
    "student_reg['date_unregistration'] = pd.to_numeric(student_reg['date_unregistration'], errors='coerce')\n",
    "\n",
    "reg_features = student_reg[['id_student','code_module','code_presentation','date_registration','date_unregistration']].copy()\n",
    "reg_features['unregistered_flag'] = reg_features['date_unregistration'].notna().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "470c1f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped rows with NA in feature list: 6827\n",
      "Dropped leakage features: ['overall_grade', 'exam_weighted', 'non_exam_weighted', 'mean_score', 'late_submissions']\n"
     ]
    }
   ],
   "source": [
    "# --- build final dataset\n",
    "final_data = (\n",
    "    student_info\n",
    "      .merge(vle_features, on=['id_student','code_module','code_presentation'], how='left')\n",
    "      .merge(assess_agg, on=['id_student','code_module','code_presentation'], how='left')\n",
    "      .merge(reg_features, on=['id_student','code_module','code_presentation'], how='left')\n",
    "      .merge(courses, on=['code_module','code_presentation'], how='left')\n",
    ")\n",
    "\n",
    "# Derived registration and engagement ratios\n",
    "if 'date_registration' in final_data.columns:\n",
    "    final_data['registered_early_flag'] = (final_data['date_registration'] < 0).astype(int)\n",
    "    final_data['registration_lead_days'] = (-final_data['date_registration']).clip(lower=0)\n",
    "\n",
    "if 'date_unregistration' in final_data.columns:\n",
    "    final_data['unregistered_flag'] = final_data['date_unregistration'].notna().astype(int)\n",
    "\n",
    "if 'module_presentation_length' in final_data.columns:\n",
    "    final_data['active_days_ratio'] = final_data['active_days'] / final_data['module_presentation_length'].replace(0, np.nan)\n",
    "    final_data['active_days_ratio'] = final_data['active_days_ratio'].fillna(0)\n",
    "\n",
    "# Drop rows with missing values in this feature list\n",
    "feature_cols = [\n",
    "    'total_sum_click','active_days','early_sum_click','early_active_days','early_click_ratio',\n",
    "    'clicks_per_active_day','early_clicks_per_active_day','early_active_ratio',\n",
    "    'distinct_sites','distinct_activity_types','activity_entropy','top_type_share',\n",
    "    'log1p_total_sum_click','log1p_early_sum_click','exam_weighted','non_exam_weighted',\n",
    "    'mean_score','late_submissions','overall_grade','unregistered_flag',\n",
    "    'registered_early_flag','registration_lead_days','active_days_ratio'\n",
    "]\n",
    "\n",
    "row_na_cols = [c for c in feature_cols if c in final_data.columns]\n",
    "if row_na_cols:\n",
    "    before = len(final_data)\n",
    "    final_data = final_data.dropna(subset=row_na_cols)\n",
    "    print('Dropped rows with NA in feature list:', before - len(final_data))\n",
    "\n",
    "# remove zero-activity rows\n",
    "zero_cols = [c for c in ['total_sum_click','active_days','early_sum_click','early_active_days','distinct_sites'] if c in final_data.columns]\n",
    "if zero_cols:\n",
    "    zero_mask = (final_data[zero_cols].sum(axis=1) == 0)\n",
    "    final_data = final_data.loc[~zero_mask].copy()\n",
    "\n",
    "# drop leakage features\n",
    "LEAKAGE_FEATURES = ['overall_grade','exam_weighted','non_exam_weighted','mean_score','late_submissions']\n",
    "leak_drop = [c for c in LEAKAGE_FEATURES if c in final_data.columns]\n",
    "if leak_drop:\n",
    "    final_data = final_data.drop(columns=leak_drop)\n",
    "    print('Dropped leakage features:', leak_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e6b280",
   "metadata": {},
   "source": [
    "## 4. H2O AutoML\n",
    "\n",
    "We run AutoML to test multiple model families and return the best models ranked by the selected metric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8a8d23",
   "metadata": {},
   "source": [
    "## 4. Baseline Models\n",
    "\n",
    "We first train a few standard models to establish a baseline before running AutoML. This gives a clear point of comparison for later tuning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d1929bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 17.0.12+8-LTS-286, mixed mode, sharing)\n",
      "  Starting server from C:\\Users\\Than Minh\\AppData\\Roaming\\Python\\Python311\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\THANMI~1\\AppData\\Local\\Temp\\tmpyv5jhnv3\n",
      "  JVM stdout: C:\\Users\\THANMI~1\\AppData\\Local\\Temp\\tmpyv5jhnv3\\h2o_Than_Minh_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\THANMI~1\\AppData\\Local\\Temp\\tmpyv5jhnv3\\h2o_Than_Minh_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Ho_Chi_Minh</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.9</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 7 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Than_Minh_9754vv</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>4 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>20</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>20</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.9 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  --------------------------------\n",
       "H2O_cluster_uptime:         01 secs\n",
       "H2O_cluster_timezone:       Asia/Ho_Chi_Minh\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.9\n",
       "H2O_cluster_version_age:    2 months and 7 days\n",
       "H2O_cluster_name:           H2O_from_python_Than_Minh_9754vv\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    4 Gb\n",
       "H2O_cluster_total_cores:    20\n",
       "H2O_cluster_allowed_cores:  20\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.9 final\n",
       "--------------------------  --------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "H2O cluster status:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>12 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Ho_Chi_Minh</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.9</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 7 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Than_Minh_9754vv</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.949 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>20</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>20</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.9 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  --------------------------------\n",
       "H2O_cluster_uptime:         12 secs\n",
       "H2O_cluster_timezone:       Asia/Ho_Chi_Minh\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.9\n",
       "H2O_cluster_version_age:    2 months and 7 days\n",
       "H2O_cluster_name:           H2O_from_python_Than_Minh_9754vv\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.949 Gb\n",
       "H2O_cluster_total_cores:    20\n",
       "H2O_cluster_allowed_cores:  20\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.9 final\n",
       "--------------------------  --------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Baseline H2O models\n",
    "h2o.init(max_mem_size='4G', verbose=True, log_level='INFO', log_dir='./h2o_logs')\n",
    "\n",
    "# Prepare H2O frame\n",
    "h2o_df = h2o.H2OFrame(final_data)\n",
    "target = 'final_result_upd_numeric'\n",
    "features = [c for c in h2o_df.columns if c != target]\n",
    "h2o_df[target] = h2o_df[target].asfactor()\n",
    "train, valid = h2o_df.split_frame(ratios=[0.8], seed=42)\n",
    "\n",
    "from h2o.estimators import H2OGradientBoostingEstimator, H2ORandomForestEstimator, H2OGeneralizedLinearEstimator\n",
    "\n",
    "baseline_models = {\n",
    "    'GLM': H2OGeneralizedLinearEstimator(family='binomial'),\n",
    "    'GBM': H2OGradientBoostingEstimator(),\n",
    "    'DRF': H2ORandomForestEstimator()\n",
    "}\n",
    "\n",
    "baseline_rows = []\n",
    "for name, model in baseline_models.items():\n",
    "    model.train(x=features, y=target, training_frame=train, validation_frame=valid)\n",
    "    perf = model.model_performance(valid=True)\n",
    "    acc = perf.accuracy()[0][1] if perf.accuracy() else None\n",
    "    f1 = perf.F1()[0][1] if perf.F1() else None\n",
    "    baseline_rows.append({'model': name, 'accuracy': acc, 'f1': f1})\n",
    "\n",
    "baseline_results = pd.DataFrame(baseline_rows).sort_values('accuracy', ascending=False)\n",
    "baseline_results\n",
    "\n",
    "\n",
    "\n",
    "print('H2O cluster status:')\n",
    "h2o.cluster().show_status()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5a330fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>27 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Ho_Chi_Minh</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.9</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 7 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Than_Minh_9754vv</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.952 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>20</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>20</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.9 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  --------------------------------\n",
       "H2O_cluster_uptime:         27 secs\n",
       "H2O_cluster_timezone:       Asia/Ho_Chi_Minh\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.9\n",
       "H2O_cluster_version_age:    2 months and 7 days\n",
       "H2O_cluster_name:           H2O_from_python_Than_Minh_9754vv\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.952 Gb\n",
       "H2O_cluster_total_cores:    20\n",
       "H2O_cluster_allowed_cores:  20\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.9 final\n",
       "--------------------------  --------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |█\n",
      "00:02:52.351: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
      "00:02:52.358: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "█████████████████████████ (cancelled)\n"
     ]
    },
    {
     "ename": "H2OJobCancelled",
     "evalue": "Job<$03017f00000132d4ffffffff$_8b90b862b444f03faa84f54df346a6> was cancelled by the user.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mH2OJobCancelled\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# AutoML search\u001b[39;00m\n\u001b[32m     18\u001b[39m aml = H2OAutoML(\n\u001b[32m     19\u001b[39m     max_runtime_secs=\u001b[32m1200\u001b[39m,\n\u001b[32m     20\u001b[39m     max_models=\u001b[32m20\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     seed=\u001b[32m42\u001b[39m\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43maml\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_frame\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_frame\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m lb = aml.leaderboard\n\u001b[32m     29\u001b[39m lb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\h2o\\automl\\_estimator.py:682\u001b[39m, in \u001b[36mH2OAutoML.train\u001b[39m\u001b[34m(self, x, y, training_frame, fold_column, weights_column, validation_frame, leaderboard_frame, blending_frame)\u001b[39m\n\u001b[32m    680\u001b[39m poll_updates = ft.partial(\u001b[38;5;28mself\u001b[39m._poll_training_updates, verbosity=\u001b[38;5;28mself\u001b[39m._verbosity, state={})\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m682\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll_updates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoll_updates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    684\u001b[39m     poll_updates(\u001b[38;5;28mself\u001b[39m._job, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\h2o\\job.py:85\u001b[39m, in \u001b[36mH2OJob.poll\u001b[39m\u001b[34m(self, poll_updates)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# check if failed... and politely print relevant message\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == \u001b[33m\"\u001b[39m\u001b[33mCANCELLED\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m H2OJobCancelled(\u001b[33m\"\u001b[39m\u001b[33mJob<\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m> was cancelled by the user.\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mself\u001b[39m.job_key)\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == \u001b[33m\"\u001b[39m\u001b[33mFAILED\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.job, \u001b[38;5;28mdict\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mstacktrace\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.job)):\n",
      "\u001b[31mH2OJobCancelled\u001b[39m: Job<$03017f00000132d4ffffffff$_8b90b862b444f03faa84f54df346a6> was cancelled by the user."
     ]
    }
   ],
   "source": [
    "# Initialize H2O\n",
    "h2o.init(max_mem_size='4G', verbose=True, log_level='INFO', log_dir='./h2o_logs')\n",
    "\n",
    "# Prepare H2O frame\n",
    "h2o_df = h2o.H2OFrame(final_data)\n",
    "\n",
    "# Set target and features\n",
    "target = 'final_result_upd_numeric'\n",
    "features = [c for c in h2o_df.columns if c != target]\n",
    "\n",
    "# Ensure target is treated as categorical\n",
    "h2o_df[target] = h2o_df[target].asfactor()\n",
    "\n",
    "# Train/valid split\n",
    "train, valid = h2o_df.split_frame(ratios=[0.8], seed=42)\n",
    "\n",
    "# AutoML search\n",
    "aml = H2OAutoML(\n",
    "    max_runtime_secs=1200,\n",
    "    max_models=20,\n",
    "    balance_classes=True,\n",
    "    sort_metric='AUC',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "aml.train(x=features, y=target, training_frame=train, validation_frame=valid)\n",
    "\n",
    "lb = aml.leaderboard\n",
    "lb\n",
    "\n",
    "\n",
    "print('H2O cluster status:')\n",
    "h2o.cluster().show_status()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47818e08",
   "metadata": {},
   "source": [
    "## 5. Evaluate top models\n",
    "\n",
    "We compute Accuracy and F1 for the top models on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561277bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate top models on validation set\n",
    "leaderboard = aml.leaderboard.as_data_frame()\n",
    "\n",
    "results = []\n",
    "for model_id in leaderboard['model_id'].head(10):\n",
    "    model = h2o.get_model(model_id)\n",
    "    perf = model.model_performance(valid=True)\n",
    "    acc = perf.accuracy()[0][1] if perf.accuracy() else None\n",
    "    f1 = perf.F1()[0][1] if perf.F1() else None\n",
    "    results.append({'model_id': model_id, 'accuracy': acc, 'f1': f1})\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values('accuracy', ascending=False)\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
